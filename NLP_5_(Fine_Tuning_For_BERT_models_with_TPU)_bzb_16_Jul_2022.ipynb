{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bzynpb/NLP/blob/main/NLP_5_(Fine_Tuning_For_BERT_models_with_TPU)_bzb_16_Jul_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3hO1LT4m8xM"
      },
      "source": [
        "# Fine Tuning For BERT Models with TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ht3aMTJ7YHgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Phh2InyWYHoL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZqjyZ92m1BZ",
        "outputId": "4c395428-a1d1-4cef-aefc-bab58bb967bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuM1yGIv3C7Q",
        "outputId": "f29f8ed4-4b8b-4ceb-ca69-f3521eecc5d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.86.139.26:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.86.139.26:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Note that the `tpu` argument is for Colab-only\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "# TPU kullaniminda cekirdek tahsislerini alabilmek icin bu kodu calistirmak gerekiyor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVPEsIFh4mpH",
        "outputId": "f6ef40f9-e73a-4583-f3e7-87af40d52367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ],
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_skoAhjLmF0E",
        "outputId": "c31ecea8-b8da-4988-d4cd-8abcf7e32172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 40.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwjqS75AeE-w"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDDYcyvBeFmA"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVecSUbKq_si"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vhy2dT_aq_f4"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/hepsiburada.csv', encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f3qQ6RJ0q_R4",
        "outputId": "04633471-e9dd-4c8a-8d7c-79a7f77e1394"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Rating                                             Review\n",
              "0       1                            3 yıldır tık demedi. :)\n",
              "1       1                      3 yıldır kullanıyorum müthiş \n",
              "2       1  Ürün bugün elime geçti çok fazla inceleme fırs...\n",
              "3       1  Almaya karar verdim. Hemencecik geldi. Keyifle...\n",
              "4       1  Günlük kullanımınızı çok çok iyi karsılıyor kı..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-206f058f-b7de-4ea7-8271-1f0671c82166\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3 yıldır tık demedi. :)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3 yıldır kullanıyorum müthiş</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Ürün bugün elime geçti çok fazla inceleme fırs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Almaya karar verdim. Hemencecik geldi. Keyifle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Günlük kullanımınızı çok çok iyi karsılıyor kı...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-206f058f-b7de-4ea7-8271-1f0671c82166')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-206f058f-b7de-4ea7-8271-1f0671c82166 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-206f058f-b7de-4ea7-8271-1f0671c82166');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKG2ol0COCu2",
        "outputId": "1bde9b8d-51e1-49e4-803b-bb916c2ddd70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    229821\n",
              "0     13676\n",
              "Name: Rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.Rating.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCQNvYfHOCga"
      },
      "outputs": [],
      "source": [
        "df.Rating = df.Rating.map({1:0, 0:1})\n",
        "# skorlari daha iyi takip edebilmek icin hedef label 1 yaptik "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emHvfDJFOMLD",
        "outputId": "fb2dfb0e-f9dd-4ab5-a3dc-5b866cddaad4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    229821\n",
              "1     13676\n",
              "Name: Rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.Rating.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNZYGlzIHvY7"
      },
      "outputs": [],
      "source": [
        "X = df['Review'].values\n",
        "y = df['Rating'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB5pzITOeltL"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVwOkzBCjmMX"
      },
      "source": [
        "### Fixing token counts of all documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXHgV6hdSBdP",
        "outputId": "e59dd5b9-3411-4cb1-95ff-39d638006fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  758\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer # AutoTokenizer tum bert modellerinde calisir\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
        "# uncased: datamda butuk tokenler kucuk harflere donusturulur, egitim kucuk harfler uzerinden yapilir\n",
        "# cased: buyuk ve kucuk harflere dikkat ederek egitir\n",
        "# translation, quastion/answer yapiliyorsa cased tercih edilir\n",
        "# uncased oldugunda turkce karakterleri okuyamiyor o yuzden manuel olarak lower yapacagiz. \n",
        "# https://huggingface.co/bert-base-uncased detayli kullanim incelemesi icin (tensorflow dikkate alarak)\n",
        "\n",
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "max_token = [] # her yorumun kac tokenden olustugunu saymak istiyoruz\n",
        "# token sayisini sayarak sonraki asamada en az kayipla kac tokene sabitlemeliyiz onu hesaplayacagiz \n",
        "\n",
        "for sent in X:\n",
        "\n",
        "    # add_special_tokens=True ile baslangic ve bitis tokenlerini ilave ediyoruz\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    \n",
        "    input_ids = tokenizer.encode(sent.lower(), #uncase turkcede calismadigi icin manuel degistirdik\n",
        "                                 add_special_tokens=True)\n",
        "    \n",
        "    max_token.append(len(input_ids))\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)\n",
        "# bert modeli en fazla 512 token hafizasinda tutuyordu\n",
        "# bizim modelimizde 758 tokenli olan veri oldugu icin hata verir "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GUA1Dsx-9ER",
        "outputId": "13fc92d6-93b4-4d0a-9107-78935c628d77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['şen', '##tepe', '##li', 'şük', '##rü', 'abi', '?', '😊']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "text = \"Şentepeli Şükrü abi?😊\".lower()\n",
        " \n",
        "tokenizer.tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB5SWy9YtxuZ",
        "outputId": "59d386ad-a437-4941-b9c2-3cdc2b5e6447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 14192, 5364, 2031, 9204, 9025, 13780, 35, 992, 3]\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Şentepeli Şükrü abi?😊\".lower()\n",
        "tokens = tokenizer.encode(sentence,\n",
        "                          add_special_tokens=True) # basina sonuna ozel tokenleri ilave et \n",
        "print(tokens)\n",
        "print(len(tokens))\n",
        "\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgq1HhDs7cPY",
        "outputId": "171ae83c-ff88-4a3f-f649-f749bd76aae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [2, 14192, 5364, 2031, 9204, 9025, 13780, 35, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Şentepeli Şükrü abi?\".lower()\n",
        "tokens = tokenizer.encode_plus(sentence,\n",
        "                               add_special_tokens=True)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1FcGviRvoM4",
        "outputId": "ecfc00a9-e681-45bb-bb53-d87d2e3c8d4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True False  True  True False False]\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "list = [5, 10, 8, 9, 12, 15]\n",
        "print(np.array(list) < 10)\n",
        "print(sum(np.array(list) < 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl9BCD__wGTk",
        "outputId": "56fcfbbf-f665-4dcb-fd46-5e7934640738"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36.4837390193719"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "np.array(max_token).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJEpW1GMUa7Q",
        "outputId": "52d20a61-c10e-4d52-8f1c-5b867dab2a1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9877000537994308"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "sum(np.array(max_token) < 160) / len(max_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "GhFdnT3ha45y"
      },
      "outputs": [],
      "source": [
        "def transformation(X):\n",
        "  # set array dimensions, hem text hem label ayri ayri boyutlandiriyorum\n",
        "  seq_len = 160 # tum yorumlarim 160 tokenden olusacak\n",
        "  num_samples = len(X) # toplam yorum sayim\n",
        "\n",
        "  # initialize empty zero arrays, sifirlardan olusan matris olusturuyorum\n",
        "  # index:yorum sayim x sutun:token sayim\n",
        "  Xids = np.zeros((num_samples, seq_len))\n",
        "  Xmask = np.zeros((num_samples, seq_len))\n",
        "\n",
        "    \n",
        "  for i, phrase in enumerate(X): # her yorumumun basina bir sayi veriyor\n",
        "\n",
        "      tokens = tokenizer.encode_plus(phrase.lower(), # encode_plus hem padding hem truncation yapar\n",
        "                                     # encode_plus benim tum ihtiyacim olan texti veriyor, \n",
        "                                     # texti hem input hem attention'a vectorel donusturebiliyorum\n",
        "                                     max_length=seq_len, # en uzun yorum 160 tokenden olusacak\n",
        "                                     truncation=True, # kirpma islemi yapacak\n",
        "                                     padding='max_length', # doldurma islemini max_lenght'e gore doldurur \n",
        "                                     # seq_len ya da 160 vs yazarsam hatali olur, orjinal haliyle kalir \n",
        "                                     # o yuzden oncelikle max_length tanimlayip onu kullanmaliyiz\n",
        "                                     add_special_tokens=True) \n",
        "      \n",
        "      # assign tokenized outputs to respective rows in numpy arrays\n",
        "      Xids[i, :] = tokens['input_ids'] # tokenizer.encode_plus kodunu calistirdiktan sonra cikan degeri aliyor\n",
        "      Xmask[i, :] = tokens['attention_mask'] # ilgili indexse attention_masktan gelen degerleri atar \n",
        "  return Xids, Xmask"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R5OSbueki6qZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "0NV4wPkfHS3h"
      },
      "outputs": [],
      "source": [
        "Xids, Xmask = transformation(X)\n",
        "# tokenizer.encode_plus kodundan cikan 'input_ids' ve 'attention_mask' degerlerimin donusturme islemini tamamladim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZoNGKMXf1Y8",
        "outputId": "aaeadd73-c8f4-43c9-a492-91035aaab806"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(243497, 160)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "Xids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZcS_JrWf1pX",
        "outputId": "ab8ceda6-f424-4859-da71-a0967712cf38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(243497, 160)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "Xmask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHRynsnl9VZo",
        "outputId": "b69d183a-ec63-467b-c9be-7aad5a785f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [2, 14192, 5364, 2031, 9204, 9025, 13780, 35, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ],
      "source": [
        "# ornek: \n",
        "sentence = \"Şentepeli Şükrü abi?\"\n",
        "tokens = tokenizer.encode_plus(sentence.lower(),\n",
        "                               max_length=20,\n",
        "                               truncation=True,\n",
        "                               padding='max_length',\n",
        "                               add_special_tokens=True)\n",
        "print(tokens)\n",
        "# 20 uzunlugunda olacak sekilde sifirlar ile doldurdu \n",
        "# kac token oldugunu 'attention_mask' ile goruyoruz "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "hcuAwwD2S-cl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLxn9zXC_H11",
        "outputId": "ccf2ecd9-bac1-40ff-d6a0-611827d12168"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "np.zeros((5, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DzAyweED5R7",
        "outputId": "69ae86d5-24d4-417a-ae17-58db54c60a9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.0000e+00, 2.3000e+01, 5.1420e+03, ..., 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00],\n",
              "       [2.0000e+00, 2.3000e+01, 5.1420e+03, ..., 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00],\n",
              "       [2.0000e+00, 2.7820e+03, 3.1200e+03, ..., 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00],\n",
              "       ...,\n",
              "       [2.0000e+00, 3.8070e+03, 9.2500e+03, ..., 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00],\n",
              "       [2.0000e+00, 3.1560e+03, 4.1650e+03, ..., 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00],\n",
              "       [2.0000e+00, 1.6807e+04, 1.9870e+03, ..., 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "Xids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC4e77awEDp5",
        "outputId": "26b5cc0c-878f-433b-84dc-e3b45510b48d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "Xmask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "25t-t9T0mVxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1ec5c5-ccc8-4262-f3a3-a01d2ad511dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "# kac label varsa matrix formatta kategoriklestiriyor\n",
        "\n",
        "l = np.array([4, 1, 2, 3, 0])\n",
        "to_categorical(l, 5) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = np.array([0,1])\n",
        "to_categorical(l,2)\n",
        "# eger data binary ise tavsiye edilen tek sutunluk hale donusturmek"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_wQtSEsmugk",
        "outputId": "53355d40-00b5-49e7-8462-bf2eb3a53ce6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrg9W-mPoUT-",
        "outputId": "f6c9885c-13b3-4e3e-ea54-a7f53a7f2acc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "np.array([1, 0, 1, 0, 0]).reshape(-1,1) \n",
        "# binary icin tavsiye edilen yontem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQSgvvRlDfE-",
        "outputId": "ec9d12f4-3556-49b2-d3ee-891e2a0ffbca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHJJhrbztBv9",
        "outputId": "ce37dfee-78e7-47c1-9dd0-bdf7a22e7818"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "labels = y.reshape(-1,1)\n",
        "# tum yorumlarim tek boyutlu matrixe donustu\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WwNbUgys-oJ",
        "outputId": "044e391e-16b7-4006-b59d-964c9a23ca5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=(TensorSpec(shape=(160,), dtype=tf.float64, name=None), TensorSpec(shape=(160,), dtype=tf.float64, name=None), TensorSpec(shape=(1,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels)) #tf.data.Dataset.from_tensors((Xids, Xmask, labels))\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFPX5acfw6vx",
        "outputId": "6543e163-44f6-4387-9e09-bb7591356bb9"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "243497"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "QPM4QFRgm_Dq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))\n",
        "\n",
        "def map_func(Xids, Xmask, labels):\n",
        "    # we convert our three-item tuple into a two-item tuple where the input item is a dictionary\n",
        "    return {'input_ids': Xids, 'attention_mask': Xmask}, labels # mutlaka dict olmali \n",
        "# neresi label-neresi input ayrim burada yapiliyor\n",
        "\n",
        "# then we use the dataset map method to apply this transformation\n",
        "dataset = dataset.map(map_func) # donusumu yapiyor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9siHyyDp_CR",
        "outputId": "d5f63ed7-95bc-4e35-9510-91cae518dcb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset element_spec=({'input_ids': TensorSpec(shape=(160,), dtype=tf.float64, name=None), 'attention_mask': TensorSpec(shape=(160,), dtype=tf.float64, name=None)}, TensorSpec(shape=(1,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "dataset\n",
        "# hangi tensor id, hangisi attention_mask muamelesi yapiyor cevapta gorebiliyoruz. Artik modelim hepsini biliyor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "token type ids (segment embeddings) hem inputumuz hem de outputumuz birer sepuantial  datadan (yani cümleden) oluşuyorsa modelin hangi cümlenin input hangi cümlenin de output olduğunu anlaması için kullandığı bir vektördür.\n",
        "- translation, soru cevap, sentence similarity modellerinde bu vektörü kullanıyoruz . Classificationda gerek duymuyoruz. çünkü outputumuz bir cümle değil sadece tek bir tokenden oluşuyor"
      ],
      "metadata": {
        "id": "mwTiX1RsVZjc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "G6CtrgIDvvX_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCuOU85Ldns6"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "1PDQLvW_m_ww"
      },
      "outputs": [],
      "source": [
        "batch_size = 32 #16\n",
        "# bert modelini tanitan makale: batch_size 31 veya 16 kullanilmasini tavsiye eder\n",
        "\n",
        "# shuffle and batch\n",
        "# fit into a batch of 32\n",
        "dataset = dataset.shuffle(243500, \n",
        "                          reshuffle_each_iteration=False).batch(batch_size, # 32li paketlere/tensorlere donusuyor\n",
        "                                                                #overfitting endisesi yoksa true diyebiliriz ama tercih edilmez !!!\n",
        "                                                                drop_remainder=True) # son batch_size icinde 32den az bir paket olabilir\n",
        "                                                                # son kalan batch_size 32'den az ise son paketi dusur. \n",
        "                                                                # ignore etmek icin de False kullanilir\n",
        "                          \n",
        "# datanin karma ve paketlere bolme islemi(batch_size) burada yapilir\n",
        "\n",
        "# reshuffle_each_iteration=False yerine true olarak kalirsa train ile egitim yaptiktan sonra \n",
        "# 1.epochtan sonra 2.epochta ilk epochta test olan traine kayar, her epochta devam eder.\n",
        "# her epochta train ve test setini degistiriyor, bu sayede overfitting controlu yapilamaz\n",
        "# false olursa test-train sabit kalir, true olursa karisir. biz sabit kalmasini tercih ediyoruz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ois7VXgq_qb",
        "outputId": "1a6b80aa-2261-4ffd-91b6-72a99e0a4013"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=({'input_ids': TensorSpec(shape=(32, 160), dtype=tf.float64, name=None), 'attention_mask': TensorSpec(shape=(32, 160), dtype=tf.float64, name=None)}, TensorSpec(shape=(32, 1), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "83GtiRjGm_6B"
      },
      "outputs": [],
      "source": [
        "# set split size (90% training data) and calculate training set size\n",
        "split = 0.9\n",
        "size = int(len(dataset)*split) #int((Xids.shape[0]/batch_size)*split)\n",
        "\n",
        "# get training and validation sets\n",
        "train_ds = dataset.take(size)\n",
        "val_ds = dataset.skip(size) # skip:geri kalan paketlerin ilgili datasetine/validation data setine gonder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nddk6eatxmYF",
        "outputId": "e7da080f-3941-4c10-c825-6f4a12d14aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7609\n",
            "6848.1\n",
            "6848\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset))\n",
        "print(len(dataset)*0.9)\n",
        "print(int(len(dataset)*0.9))\n",
        "# datada 7609 adet 32li paket var\n",
        "# bu paketlerin %90ini (6.848) train setine aticam, kalani teste gondericem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqlVuZg8KeSK",
        "outputId": "e4142cd9-6e7b-4353-9ddf-e77c59dd0682"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(243497, 160)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "Xids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1Z2kkoczyvP",
        "outputId": "0f4dd2ad-81b0-4f41-df25-13455ff773ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7609"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "#batch_size=32\n",
        "int(Xids.shape[0]/batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrDXF1ibl76v"
      },
      "source": [
        "## Creating Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "p__xkFOt4_oI"
      },
      "outputs": [],
      "source": [
        "## modeli func olarak tanimlayip sonra calistirmaliyiz\n",
        "# TPU cekirdeklerin hizindan faydalanabilmek icin \n",
        "def create_model():\n",
        "    from transformers import TFAutoModel ## model import etme ve yazma mutlaka def icinde olmali\n",
        "                                         # def disinda yazilmasi halinde def fonksiyonu kullaniminda hata verir\n",
        "    model = TFAutoModel.from_pretrained(\"dbmdz/bert-base-turkish-cased\") # tokenizasion isleminde ne kullandiysak aynen kullanilmali\n",
        "    # tavsiye edilen automodel\n",
        "    #TFAutoModel tensorflow kutuphanesinin islemleriyle devam edebilmek icin tfautomodel kullandik\n",
        "\n",
        "\n",
        "    input_ids = tf.keras.layers.Input(shape=(160,), # sabit boyut ne ise o kullanilmali\n",
        "                                      # her yorum tek satirlik gelecegi icin model tek satirlik islem yapiyor\n",
        "                                      name='input_ids', # tensorflow icine verdigimiz isimler ne ise aynen kullanilmali\n",
        "                                      dtype='int32') # \n",
        "    \n",
        "    attention_mask = tf.keras.layers.Input(shape=(160,),\n",
        "                                           name='attention_mask', # tensorflow icinde verdilen isimler kullanilmaz ise hata verir\n",
        "                                           dtype='int32')\n",
        "\n",
        "    embeddings = model.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)[\"pooler_output\"] #[1] en son layerda, egitim sonrasi bunyesinde tuttugu tum embedingleri cekiyor \n",
        "                            # butun word_embeddingleri burada olusturuyorum\n",
        "\n",
        "    x = tf.keras.layers.Dense(160, activation='relu')(embeddings) # sequential modellerde model.add derdik \n",
        "                                                                  # burada modelin eklenmesi farkli \n",
        "                                                                  # overfittin gidermek icin danse layer noron sayisini azaltabiliriz\n",
        "\n",
        "    x = tf.keras.layers.Dropout(0.2, name=\"dropout\")(x) #0.1 # yukaridaki layer'i alip dropout uygular\n",
        "\n",
        "    y = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(x) # en son tahmin yapilacak dense layer'a aktar\n",
        "                                                # dropout 0.1 degeri tavsiye edilen deger \n",
        "\n",
        "    ## Functional API\n",
        "    ## Sequential yapi yok, hazir veri cekildigi icin bu yapi kullaniliyor\n",
        "\n",
        "    return tf.keras.Model(inputs=[input_ids, attention_mask], outputs=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPRqyWNQDzyb",
        "outputId": "2e9e8d43-ee96-40c7-8842-dc1821f7d746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-turkish-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  \n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5) #3e-5, 5e-5\n",
        "  loss = tf.keras.losses.BinaryCrossentropy()\n",
        "  recall = tf.keras.metrics.Recall()\n",
        "  model3 = create_model()\n",
        "  model3.compile(optimizer=optimizer, loss=loss, metrics=[recall])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "GHBMQ5bTxL4o"
      },
      "outputs": [],
      "source": [
        "#pd.Series(y).value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "GpqDx2KRxNpj"
      },
      "outputs": [],
      "source": [
        "#weights = {0:0.05, 1:0.95}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLEyg_TUVTXn",
        "outputId": "4cf22fe5-ef3d-4e1c-be35-5818740c0408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 160)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 160)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  110617344   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 160,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 160)          123040      ['bert[0][1]']                   \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 160)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 1)            161         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 110,740,545\n",
            "Trainable params: 110,740,545\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxZ_YPsK61ll",
        "outputId": "f36a86b6-b290-48d7-a181-c25a50341bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1508/6848 [=====>........................] - ETA: 7:16 - loss: 0.0993 - recall_2: 0.5742"
          ]
        }
      ],
      "source": [
        "history = model3.fit(train_ds,\n",
        "                     validation_data= val_ds,\n",
        "                     epochs=1) #epoch= 2 or 3 # overfittinge gitmemek icin 2 veya 3 kullanim tavsiye edilir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjsWW1VAmPxK"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po2U0-F_D1ks",
        "outputId": "acca3cc4-8c83-44e3-ffcb-2908fd36fbc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99     22988\n",
            "           1       0.84      0.76      0.80      1364\n",
            "\n",
            "    accuracy                           0.98     24352\n",
            "   macro avg       0.91      0.88      0.89     24352\n",
            "weighted avg       0.98      0.98      0.98     24352\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# y_train ve y_test yoktu \n",
        "# yukarida shuffle ederken neye gore karistigini, hangi indexlere tekabul ettigini da bilmiyoruz. \n",
        "# y_pred karsilastiracak degerimiz olmadigi icin val_ds'den yararlaniriz\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = model3.predict(val_ds) >= 0.5 # \n",
        "\n",
        "y_test = []\n",
        "for i in val_ds:\n",
        "  for j in np.array(i[1]):\n",
        "    y_test.append(j)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiPDFzwmdknu",
        "outputId": "897e8003-a2f8-4694-8078-21bf9e89b609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    206825\n",
            "           1       0.91      0.84      0.87     12311\n",
            "\n",
            "    accuracy                           0.99    219136\n",
            "   macro avg       0.95      0.92      0.93    219136\n",
            "weighted avg       0.99      0.99      0.99    219136\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_train_pred = model3.predict(train_ds) >= 0.5\n",
        "\n",
        "y_train = []\n",
        "for i in train_ds:\n",
        "  for j in np.array(i[1]): # data icinde gecen tum labelleri cekiyorum\n",
        "    y_train.append(j) # labelleri cekerek y_train olusturuyorum\n",
        "\n",
        "print(classification_report(y_train, y_train_pred)) \n",
        "\n",
        "# her bir tensorden (32li paketli datadan) gercek degerleri alarak y_traine manuel olarak atiyorum\n",
        "# tensoru array yapinca daha hizli calisiyor "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model3.predict(train_ds)>=0.5\n",
        "\n",
        "y_test = [j for i in train_ds for j in np.array(i[1])]\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfF5zJgZjrEY",
        "outputId": "70b0cef3-6f74-462d-f2d4-ecd57a360a89"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    206825\n",
            "           1       0.91      0.84      0.87     12311\n",
            "\n",
            "    accuracy                           0.99    219136\n",
            "   macro avg       0.95      0.92      0.93    219136\n",
            "weighted avg       0.99      0.99      0.99    219136\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZogPcBjND7i",
        "outputId": "94e8181e-91c3-4521-f763-b008131573ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SkipDataset element_spec=({'input_ids': TensorSpec(shape=(32, 160), dtype=tf.float64, name=None), 'attention_mask': TensorSpec(shape=(32, 160), dtype=tf.float64, name=None)}, TensorSpec(shape=(32, 1), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "val_ds # bir yoruma ait verilerim \n",
        "# berk modele datami 32lik paketler halinde verdim, bu paketlerden 1 degeri :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh-OJF74AbAY",
        "outputId": "833a8eba-f35a-47fd-9b5d-25db0f2ea5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ],
      "source": [
        "for i in val_ds:\n",
        "  print(np.array(i[1])) # sadece label kismiyla ilgilendigim ixin \n",
        "  break\n",
        "\n",
        "  # gercek y_test degerim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-tHJBFfLVVcp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kudkOYjaXcMS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "c06b144f-fb3f-4a91-9e6b-82cdf38dac15"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-391ea584fd5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     class_weight=weights)\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
          ]
        }
      ],
      "source": [
        " #Ağırlıklandırılmış Model ---> dropout(0,1), batchsize = 16, epoch =1, learning rate = 2e-5\n",
        " \n",
        "#  TEST SET\n",
        "#                 precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.99      0.97      0.98     22987\n",
        "#            1       0.63      0.89      0.74      1365\n",
        "\n",
        "#     accuracy                           0.96     24352\n",
        "#    macro avg       0.81      0.93      0.86     24352\n",
        "# weighted avg       0.97      0.96      0.97     24352\n",
        "\n",
        "# TRAIN SET\n",
        "#                 precision    recall  f1-score   support\n",
        "\n",
        "#            0       1.00      0.97      0.99    206825\n",
        "#            1       0.69      0.95      0.80     12311\n",
        "\n",
        "#     accuracy                           0.97    219136\n",
        "#    macro avg       0.84      0.96      0.89    219136\n",
        "# weighted avg       0.98      0.97      0.98    219136\n",
        "\n",
        "\n",
        "\n",
        "history = model3.fit(train_ds,\n",
        "                     validation_data= val_ds,\n",
        "                     epochs=1,\n",
        "                     class_weight=weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz2gWXxbXcXr"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVdM_75GXciM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ZFRpVxcuOyk5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "90f3af10-5150-4c9d-898b-8aaf60446844"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-e456254b517e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'k--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \"\"\"\n\u001b[1;32m    858\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m     )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [219136, 24352]"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_pred_proba = model3.predict(val_ds)\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "plt.plot([1,0],[0,1],'k--')\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('recall')\n",
        "plt.ylabel('precision')\n",
        "plt.title('precision recall curve')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2X-rrucPPrX"
      },
      "outputs": [],
      "source": [
        "average_precision_score(y_test, y_pred_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B6Sv63_H3we"
      },
      "outputs": [],
      "source": [
        "model3.save(\"sentiment_model_without_weighted.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_2ErgJnLKV0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "model4 = load_model('/content/drive/MyDrive/sentiment_model_without_weighted.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaARaSiXEstW"
      },
      "outputs": [],
      "source": [
        "# initialize tokenizer from transformers\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "\n",
        "tokenizers = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
        "\n",
        "def prep_data(text):\n",
        "    # tokenize to get input IDs and attention mask tensors\n",
        "    tokens = tokenizers.encode_plus(text.lower(), max_length=160,\n",
        "                                   truncation=True, padding='max_length',\n",
        "                                   add_special_tokens=True,\n",
        "                                   return_tensors='tf')\n",
        "  \n",
        "    return {'input_ids': tokens['input_ids'],      #tf.cast(tokens['input_ids'], tf.int32)\n",
        "            'attention_mask': tokens['attention_mask']} #tf.cast(tokens['attention_mask'], tf.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tbmF2a5QZHD"
      },
      "outputs": [],
      "source": [
        "review1 = \"çok beğendim herkese tavsiye ederim\"\n",
        "review2 = \"süper ürün aynı gün elime geçti\"\n",
        "review3 = \"büyük bir hayal kırıklığı yaşadım bu ürünü bu markaya yakıştıramadım\"\n",
        "review4 = \"kelimelerle tarif edilemez\"\n",
        "review5 = \"tasarımı harika ancak kargo çok geç geldi ve ürün açılmıştı hayal kırıklığı gerçekten\"\n",
        "review6 = \"hiç resimde gösterildiği gibi değil\"\n",
        "review7 = \"kötü yorumlar gözümü korkutmuştu ancak hiçbir sorun yaşamadım teşekkürler\"\n",
        "review8 = \"hiç bu kadar kötü bir satıcıya denk gelmemiştim ürün siparişimi iptal ediyorum\"\n",
        "review9 = \"tam bir fiyat performans ürünü\"\n",
        "review10 = \"beklediğim gibi çıkmadı\"\n",
        "review11 = \"on numara beş yıldız\"\n",
        "review12 = \"bu kargoyu biran önce bırakın. yoksa üründe sıkıntı yok\"\n",
        "review13 = \"televizyonun görüntü kalitesi çok kötü, dün akşam evde arkadaşlarla toplandık. yedik, içtik, sohbet ettik. Sonra televizyonda Türkiye - İngiltere maçını seyrettik. \"\n",
        "review14 = '1 gün gibi kısa bir sürede elime geçti. Ve bu fıyata süper bir ürün tavsiye ederim. Lakin eli büyük olan kişiler daha büyük modelini tercih edebilirler ortaboy ürün. Teşekkürler '\n",
        "review15 = \"alınca anlarsın anyayı konyayı\"\n",
        "review16 = \"çöpe atacak paran varsa alabilirsin\"\n",
        "review17= \"Telefon fena değil\"\n",
        "review18 = \"al da gününü gör\"\n",
        "review19 = \"Ürün süper ama satıcı ve kargo berbat\"\n",
        "review20= \"kargo süper ama ürün berbat\"\n",
        "review21 = \"Aldigim TV cok kaliteli diye dusunmustum, sonradan cok da iyi bir TV olmadigini dusundum, ama neyse yine de memnunum.\"\n",
        "review22 = \"😊\"\n",
        "review23 = \":)\"\n",
        "review24= \"I ❤️ you\"\n",
        "reviews = [review1, review2, review3, review4, review5, review6, review7, review8, review9, review10, review11, review12, review13, review14, review15, review16, review17, review18, review19, review20, review21, review22, review23, review24]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fecjxatQayR"
      },
      "outputs": [],
      "source": [
        "probs = []\n",
        "for i in reviews:\n",
        "\n",
        "  in_tensor = prep_data(i) \n",
        "\n",
        "  prob = model4.predict(in_tensor)[0][0]\n",
        "\n",
        "  probs.append(prob)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_tensor"
      ],
      "metadata": {
        "id": "yZ41unnxp3XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdtIuEtRBvqB"
      },
      "outputs": [],
      "source": [
        "model4.predict(in_tensor)\n",
        "# bana olasilik donduruyor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMaJLPfQEwlz"
      },
      "outputs": [],
      "source": [
        "probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxgMYBczYyNC"
      },
      "outputs": [],
      "source": [
        "classes  = (np.array(probs) >= 0.5).astype(\"int\")\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgH72FPhYyBr"
      },
      "outputs": [],
      "source": [
        "my_dict = {\"Review\":reviews, \"prob\":probs, \"classes\":classes}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLeukDeMYx1o"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.DataFrame(my_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "for i in X:\n",
        "  if \"gününü gör\" in i.lower():\n",
        "    count+=1\n",
        "print(count)"
      ],
      "metadata": {
        "id": "d5ImVzx1sBVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hGjWw_xgsQVa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NLP_5_(Fine_Tuning_For_BERT_models_with_TPU)-bzb-16_Jul_2022.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}